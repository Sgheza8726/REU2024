/home/efleisig/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Map: 100%|█████████████████████████████████████| 2701/2701 [00:00<00:00, 3754.71 examples/s]
Maximum token ID in the dataset: 128256
Vocabulary size of the model: 128000

Loading checkpoint shards: 100%|██████████████████████████████| 4/4 [00:02<00:00,  1.66it/s]
  0%|                                                               | 0/507 [00:00<?, ?it/s]Traceback (most recent call last):
  File "/home/efleisig/sams_reu/llama3_train.py", line 80, in <module>
    trainer.train()
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2813, in compute_loss
    raise ValueError(
ValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.
Traceback (most recent call last):
  File "/home/efleisig/sams_reu/llama3_train.py", line 80, in <module>
    trainer.train()
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1539, in train
    return inner_training_loop(
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 1869, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2772, in training_step
    loss = self.compute_loss(model, inputs)
  File "/home/efleisig/.local/lib/python3.10/site-packages/transformers/trainer.py", line 2813, in compute_loss
    raise ValueError(
ValueError: The model did not return a loss from the inputs, only the following keys: logits,past_key_values. For reference, the inputs it received are input_ids,attention_mask.